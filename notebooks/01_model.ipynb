{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchshow as ts\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torchshow as ts\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvianNatureSounds(Dataset):\n",
    "    def __init__(self, annotation_file=None, root_dir='./',mel_spectrogram = None,mode='wav'):\n",
    "        self.annotation_file = pd.read_csv(annotation_file).sort_values('fileName')\n",
    "        self.root_dir = root_dir\n",
    "        self.mel_transformation = mel_spectrogram\n",
    "        self.AmplitudeToDB = torchaudio.transforms.AmplitudeToDB()\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotation_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'wav':\n",
    "            audio_sample_path = os.path.join(self.root_dir,os.listdir(self.root_dir)[index])\n",
    "            label = self.annotation_file.iloc[index]['habitat']\n",
    "            signal, sr = torchaudio.load(audio_sample_path)\n",
    "\n",
    "            return (signal, sr), label , audio_sample_path\n",
    "        \n",
    "        elif self.mode == 'mel':\n",
    "            audio_sample_path = os.path.join(self.root_dir,os.listdir(self.root_dir)[index])\n",
    "            label = self.annotation_file.iloc[index]['habitat']\n",
    "            signal, sr = torchaudio.load(audio_sample_path)\n",
    "            signal = self.AmplitudeToDB(self.mel_transformation(signal))\n",
    "\n",
    "            # signal[:, 65:] = 0\n",
    "\n",
    "            # return (signal, sr), label\n",
    "            return signal, label\n",
    "        \n",
    "        elif self.mode == 'stft': \n",
    "            audio_sample_path = os.path.join(self.root_dir,os.listdir(self.root_dir)[index])\n",
    "            label = self.annotation_file.iloc[index]['habitat']\n",
    "            signal, sr = torchaudio.load(audio_sample_path)\n",
    "\n",
    "            stft = torch.stft(signal, n_fft=1024, hop_length=512, normalized=True, return_complex=True)\n",
    "\n",
    "            mag = self.AmplitudeToDB(torch.abs(stft))\n",
    "            phase = torch.angle(stft)\n",
    "\n",
    "            return torch.cat([mag,phase],dim=0), label\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearInterpolation(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(LinearInterpolation, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode='bilinear', align_corners=False)\n",
    "\n",
    "\n",
    "\n",
    "class SimpleVariationalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleVariationalAutoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 512, kernel_size=3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.linsys = nn.Sequential(\n",
    "            nn.Linear(56320, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 128))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            LinearInterpolation(scale_factor=2),\n",
    "            nn.ConvTranspose2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            LinearInterpolation(scale_factor=2),\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "             LinearInterpolation(scale_factor=2),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            LinearInterpolation(scale_factor=2),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.linsys2 = nn.Sequential(\n",
    "            nn.Linear(128, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4096, 56320))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        mu, sigma = self.linsys(x), self.linsys(x)\n",
    "\n",
    "        return mu, sigma\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.linsys2(z)\n",
    "\n",
    "        z = z.reshape(z.shape[0],512,5,-1)\n",
    "\n",
    "        # print(z.shape)\n",
    "\n",
    "        x_recon = self.decoder(z)\n",
    "\n",
    "        # print(x_recon.shape)\n",
    "        \n",
    "        return x_recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encode(x)\n",
    "        z = mu + sigma * torch.randn_like(sigma)\n",
    "\n",
    "        x_recon = self.decode(z)\n",
    "\n",
    "        return x_recon, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleVariationalAutoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DataLoader: \n",
    "torchaudio.set_audio_backend(backend='sox_io')\n",
    "\n",
    "kwargs = {\n",
    "    'sample_rate': 16000,\n",
    "    'n_fft': 1024,\n",
    "    'hop_length': 512,\n",
    "    'n_mels': 80\n",
    "    # Add any other keyword arguments here\n",
    "}\n",
    "\n",
    "mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=16000,\n",
    "                                     n_fft=1024,\n",
    "                                     hop_length=4096*2,\n",
    "                                     n_mels=80)\n",
    "\n",
    "\n",
    "\n",
    "data = AvianNatureSounds(annotation_file='../data/AvianID_AcousticIndices/UK_AI.csv',root_dir='../data/UK_BIRD/',mel_spectrogram=mel_spectrogram,mode='mel')\n",
    "\n",
    "train_loader = DataLoader(dataset=data, batch_size=4, shuffle=True)\n",
    "batch = next(iter(train_loader)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch[0][0][0].shape)\n",
    "\n",
    "librosa.display.specshow(batch[0][0][0].numpy(),\n",
    "                         sr=48000,\n",
    "                         x_axis='time',\n",
    "                         y_axis='mel')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu, sigma = model.encode(batch[0][0])\n",
    "# z = mu + sigma * torch.randn_like(sigma)\n",
    "\n",
    "# x_recon = model.decode(z)\n",
    "\n",
    "\n",
    "# x_recon[0][0].shape\n",
    "\n",
    "# model(batch[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(x_recon[0][0].detach().numpy(),\n",
    "#                          sr=48000,\n",
    "#                          x_axis='time',\n",
    "#                          y_axis='mel')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "# Dataloader & Device\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "NUM_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "LR_RATE = 5e-5 # kaparthy constant\n",
    "\n",
    "#model\n",
    "model = SimpleVariationalAutoencoder()\n",
    "model.to(device)\n",
    "\n",
    "# dataloader\n",
    "data = AvianNatureSounds(annotation_file='../data/AvianID_AcousticIndices/UK_AI.csv',root_dir='../data/UK_BIRD/',mel_spectrogram=mel_spectrogram,mode='mel')\n",
    "train_loader = DataLoader(dataset=data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "optimiser = optim.Adam(model.parameters(),lr=LR_RATE)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    loop = tqdm(enumerate(train_loader))\n",
    "    for i, (x, _) in loop:\n",
    "        # Forward pass\n",
    "        x = x.to(device)\n",
    "        x_reconstructed, mu, sigma = model(x)\n",
    "\n",
    "        # Compute Loss\n",
    "        reconstruction_loss = loss_fn(x_reconstructed,x)\n",
    "        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2)-sigma.pow(2))\n",
    "\n",
    "        # backprop\n",
    "        if epoch < 25:\n",
    "            loss = reconstruction_loss\n",
    "\n",
    "        else:\n",
    "            loss = reconstruction_loss + kl_div\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "librosa.display.specshow(x[1][0].cpu().detach().numpy(),\n",
    "                         sr=48000,\n",
    "                         x_axis='time',\n",
    "                         y_axis='mel')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "atod = torchaudio.transforms.AmplitudeToDB()\n",
    "librosa.display.specshow(x_reconstructed[1][0].cpu().detach().numpy(),\n",
    "                         sr=48000,\n",
    "                         x_axis='time',\n",
    "                         y_axis='mel')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reconstructed.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
