{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,generator=True,use_act=True,use_bn=True,**kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.use_act = use_act\n",
    "        self.cnn = nn.Conv2d(in_channels, out_channels, bias=not use_bn, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) if use_bn else nn.Identity()\n",
    "        self.act = (nn.PReLU(num_parameters=out_channels) if generator else nn.LeakyReLU(0.2, inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.cnn(x))) if self.use_act else self.bn(self.cnn(x))\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block1 = ConvBlock(in_channels,in_channels,kernel_size=3,stride=1,padding=1)\n",
    "        self.block2 = ConvBlock(in_channels,in_channels,kernel_size=3,stride=1,padding=1,use_act=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "\n",
    "        return out + x\n",
    "\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self,in_channels,scale_factor=2):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,in_channels * scale_factor ** 2,3,1,1)\n",
    "        self.ps = nn.PixelShuffle(scale_factor)\n",
    "        self.act = nn.PReLU(num_parameters=in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,in_channels=3,out_channels=64,num_blocks=16):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = ConvBlock(in_channels,out_channels,kernel_size=9, stride=1, padding=4,use_bn=False)\n",
    "        self.residuals = nn.Sequential(*[ResBlock(out_channels) for _ in range(num_blocks)])\n",
    "        self.convblock = ConvBlock(out_channels,out_channels,kernel_size=3,stride=1,padding=1,use_act=False)\n",
    "        self.upsamples = nn.Sequential(Upsample(out_channels),Upsample(out_channels))\n",
    "        self.final = nn.Conv2d(in_channels=64,out_channels=3,kernel_size=9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self,x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.residuals(initial)\n",
    "        x = self.convblock(x)\n",
    "        x = x + initial\n",
    "        x = self.upsamples(x)\n",
    "        return torch.tanh(self.final(x))\n",
    "    \n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self,in_channels=3,featrues=[64,64,128,128,256,256,512,512]):\n",
    "        super(Critic, self).__init__()\n",
    "        block_list = []\n",
    "\n",
    "        for idx, feature in enumerate(featrues):\n",
    "            block_list.append(ConvBlock(in_channels=in_channels,\n",
    "                                    out_channels=feature,\n",
    "                                    kernel_size=3,\n",
    "                                    stride=1 + idx % 2,\n",
    "                                    padding=1,\n",
    "                                    generator=False,\n",
    "                                    use_act=True,\n",
    "                                    use_bn=False if idx == 0 else True))\n",
    "            in_channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*block_list)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6,6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*6*6,1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024,1),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tests passed!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    low_res = 128\n",
    "    disc = Critic()\n",
    "    gen = Generator()\n",
    "    x = torch.randn((4,3,low_res,low_res))\n",
    "    bz,c  = x.shape[0],x.shape[1]\n",
    "    gen_out = gen(x)\n",
    "    assert gen_out.shape == (bz,c,low_res*4,low_res* 4)\n",
    "    disc_out = disc(gen_out)\n",
    "    assert disc_out.shape == (bz,1)\n",
    "    return 'Tests passed!'\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "import torch\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "LOAD_MODEL = True\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_GEN = \"../data/checkpoints/gen.pth.tar\"\n",
    "CHECKPOINT_DISC = \"../data/checkpoints/disc.pth.tar\"\n",
    "DEVICE = device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "HIGH_RES = 96\n",
    "LOW_RES = HIGH_RES // 4\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "\n",
    "# phi_5,4 5th conv layer before maxpooling but after activation\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg19(pretrained=True).features[:36].eval().to(DEVICE)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        vgg_input_features = self.vgg(input)\n",
    "        vgg_target_features = self.vgg(target)\n",
    "        return self.loss(vgg_input_features, vgg_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
