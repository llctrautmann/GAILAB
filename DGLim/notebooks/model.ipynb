{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_complex_tensor(tensor):\n",
    "    if tensor.isinstance(torch.Tensor):\n",
    "        tensor = tensor.detach()\n",
    "    else:\n",
    "        pass\n",
    "    # Separate the real and imaginary parts of the complex tensor\n",
    "    real = tensor.abs()\n",
    "    imag = tensor.angle()\n",
    "    amptodb = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    # Create a grid of subplots for real and imaginary parts\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Plot the real part\n",
    "    im1 = axs[0].imshow(amptodb(real), cmap='magma')\n",
    "    axs[0].set_title('Mag')\n",
    "\n",
    "    # Plot the imaginary part\n",
    "    im2 = axs[1].imshow(imag, cmap='Blues')\n",
    "    axs[1].set_title('Phase')\n",
    "\n",
    "    # Add color bar\n",
    "    fig.colorbar(im1, ax=axs[0])\n",
    "    fig.colorbar(im2, ax=axs[1])\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def frequency_shift(stft, sr, N=513, L=512):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a time-frequency grid for the frequency shift\n",
    "    k = np.arange(N)[:, None]  # Frequency bin indices, column vector\n",
    "    l = np.arange(stft.shape[1])  # Frame indices\n",
    "    \n",
    "    freq_shift = np.exp(-1j * (2 * np.pi/ N) * k * l * L )\n",
    "    \n",
    "    # Shift to baseband\n",
    "    baseband_stft_matrix = stft * freq_shift\n",
    "    \n",
    "    # Calculate and unwrap phase\n",
    "    phase = np.angle(baseband_stft_matrix)\n",
    "    unwrapped_phase = np.unwrap(phase, axis=1)  # Unwrap phase along the time axis\n",
    "    \n",
    "    # Calculate phase difference between neighboring frames\n",
    "    phase_diff = np.diff(unwrapped_phase, axis=1)\n",
    "    \n",
    "    return phase_diff\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convGLU(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, kernel_size=(7,7), padding='same', batchnorm=False):\n",
    "        super().__init__()\n",
    "        if padding == 'same':\n",
    "            padding = (kernel_size[0]//2, kernel_size[1]//2)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * 2, kernel_size, padding=padding)  # 2D convolutional layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
    "        if batchnorm:\n",
    "            self.conv = nn.Sequential(\n",
    "                self.conv,\n",
    "                nn.BatchNorm2d(out_channels * 2)  # Batch normalization layer\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Apply convolutional layer\n",
    "        channel = x.shape[1]  # Get the number of channels\n",
    "\n",
    "        x = x[:, :channel//2, :, :] * self.sigmoid(x[:, channel//2:, :, :])  # Apply GLU (Gated Linear Unit)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self,padding=None,additional_conv=False):\n",
    "        super().__init__()\n",
    "        self._hidden_channels = 32\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(6, self._hidden_channels, (11,11), padding=padding) if additional_conv else nn.Identity(), # in_channel = 6 because we concatenate the real and imag part of the complex spectrogram\n",
    "            convGLU(self._hidden_channels if additional_conv else 6, self._hidden_channels, (11,11), padding='same'))\n",
    "        \n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv2d(self._hidden_channels, self._hidden_channels, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels, self._hidden_channels, (7,3), padding='same'),\n",
    "            nn.Conv2d(self._hidden_channels, self._hidden_channels, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels, self._hidden_channels, (7,3), padding='same'),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(self._hidden_channels, 1, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels,self._hidden_channels, (7,3), padding='same'),\n",
    "            nn.Conv2d(self._hidden_channels, 2, (7,3), padding=(7//2, 3//2)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = torch.cat([x,y,z],dim=1)\n",
    "        x = self.initial(x)\n",
    "        residual = x\n",
    "        x = self.mid(x)\n",
    "        x += residual\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DeepGriffinLim(nn.Module):\n",
    "    def __init__(self,blocks=10, n_fft=1024, hop_size=512, win_size=1024, window='hann_window'):\n",
    "        super().__init__()\n",
    "        self.dnn_blocks = nn.ModuleList([DNN() for _ in range(blocks)]) # DNN blocks\n",
    "\n",
    "\n",
    "    def stft(self, x, n_fft=1024, hop_size=512, win_size=1024):\n",
    "        return torch.stft(x, n_fft=n_fft, hop_length=hop_size, win_length=win_size, return_complex=True)\n",
    "\n",
    "    def istft(self, x, n_fft=1024, hop_size=512, win_size=1024):\n",
    "        return torch.istft(x, n_fft=n_fft, hop_length=hop_size, win_length=win_size)\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # EXPERIMENTAL FUNCTIONS ###################\n",
    "    ############################################\n",
    "    def swap_in_mag(self,mag, x):\n",
    "        phase = torch.angle(x)\n",
    "        real_part = mag * torch.cos(phase)\n",
    "        imaginary_part = mag * torch.sin(phase)\n",
    "        new_tensor = torch.cat([real_part, imaginary_part], dim=-1)  # adjust dim as per your needs\n",
    "        return new_tensor\n",
    "\n",
    "    def final_mag_swap(self, mag, x):\n",
    "        phase = torch.angle(x)\n",
    "        return torch.cat([mag * torch.cos(phase), mag * torch.sin(phase)], dim=1), torch.cat([mag, phase], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    def swap_in_true_mag(self, x, mag,final=False):\n",
    "        phase = torch.angle(x)\n",
    "        # return torch.cat([mag * torch.cos(phase), mag * torch.sin(phase)], dim=1) # legacy\n",
    "        if final:\n",
    "            return torch.cat([mag * torch.cos(phase), mag * torch.sin(phase)], dim=1)\n",
    "        else:\n",
    "            return  mag + 1j * phase\n",
    "\n",
    "    ############################################\n",
    "    ############################################\n",
    "    ############################################\n",
    "\n",
    "\n",
    "    def forward(self, x, mag, added_depth=1):\n",
    "        layer_outputs = []\n",
    "\n",
    "        for _ in range(added_depth):\n",
    "            for subblock in self.dnn_blocks:\n",
    "                # step one is the P_a step\n",
    "                \n",
    "                y_tilda = self.swap_in_mag(x_tilda, mag)\n",
    "                z_tilda = self.stft(self.istft(y_tilda.squeeze(1)))\n",
    "\n",
    "                dnn_in = self.transform_to_float([x_tilda, y_tilda, z_tilda.unsqueeze(1)])\n",
    "                dnn_out = subblock(dnn_in)\n",
    "\n",
    "                residual  = dnn_out[:,0,...] + 1j * dnn_out[:,1,...]\n",
    "\n",
    "                x = (z_tilda - residual).unsqueeze_(1)\n",
    "\n",
    "                layer_outputs.append(x)\n",
    "\n",
    "        return layer_outputs, self.swap_in_true_mag(x, mag,final=True), residual\n",
    "\n",
    " \n",
    "    @staticmethod\n",
    "    def transform_to_float(tensor_list: list):\n",
    "        output = []\n",
    "        for idx, i in enumerate(range(len(tensor_list))):\n",
    "            if tensor_list[i].dtype == torch.complex64 and tensor_list[i].dim() == 4:\n",
    "                output.append(torch.cat([tensor_list[i].real, tensor_list[i].imag], dim=1))\n",
    "            else:\n",
    "                print(f'Input {idx} is not a complex tensor with 4 dimensions')\n",
    "                return None\n",
    "\n",
    "        return torch.cat(output, dim=1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGL = DeepGriffinLim(blocks=10)\n",
    "\n",
    "# mag = torch.randn(4,1,513,50,dtype=torch.float32)\n",
    "# x = torch.randn(4,1,513,50,dtype=torch.complex64)\n",
    "\n",
    "# tens = DGL(x,mag)\n",
    "\n",
    "# print(tens.dtype)\n",
    "\n",
    "# phase = torch.angle(x)\n",
    "\n",
    "# sample = torch.cat([mag * torch.cos(phase), mag * torch.sin(phase)], dim=1)\n",
    "# torch.nn.MSELoss(reduction='mean')(sample, tens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def swap_in_true_mag(x, mag):\n",
    "#     '''\n",
    "#     For the short time fourier transform, to work with batched data\n",
    "#     we need to remove the channel dimension and add it back after. We\n",
    "#     still need an 4D tensor for the DNN to work properly. This means,\n",
    "#     that the dimension needs to be reduced after the swap and expanded\n",
    "#     again before the DNN. This entire cell is just a conformation, that\n",
    "#     this is the necessary proceedure. \n",
    "#     '''\n",
    "#     phase = torch.angle(x)\n",
    "#     # return torch.cat([mag * torch.cos(phase), mag * torch.sin(phase)], dim=1) # legacy\n",
    "#     return  (mag + 1j * phase).squeeze_(1)\n",
    "\n",
    "\n",
    "# x = torch.randn(16,1,513,1024, dtype=torch.complex64)\n",
    "# mag = torch.randn(16,1,513,1024, dtype=torch.float32)\n",
    "\n",
    "# out = swap_in_true_mag(x,mag)\n",
    "# print(f'OUT SHAPE: {out.shape}')\n",
    "# print(f'OUT TYPE: {out.dtype}')\n",
    "\n",
    "\n",
    "# istft = torch.istft(out, n_fft=1024, hop_length=512, win_length=1024)\n",
    "# print(f'ISTFT shape: {istft.shape}')\n",
    "# print(f'ISTFT dtype: {istft.dtype}')\n",
    "\n",
    "# stft = torch.stft(istft, n_fft=1024, hop_length=512, win_length=1024,return_complex=True)\n",
    "# print(f'STFT shape: {stft.shape}')\n",
    "# print(f'STFT dtype: {stft.dtype}')\n",
    "\n",
    "# # print(f'unsqueezed stft shape: {stft.unsqueeze_(1).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DGLim.data import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "ds = AvianNatureSounds(annotation_file_path=hp.annotation_file_path,\n",
    "                       root_dir=hp.root_dir,\n",
    "                       key=hp.key,\n",
    "                       mode=hp.mode,\n",
    "                       length=15,\n",
    "                       sampling_rate=hp.sampling_rate,\n",
    "                       n_fft=hp.n_fft,\n",
    "                       hop_length=hp.hop_length,\n",
    "                       mel_spectrogram=hp.mel_spectrogram,\n",
    "                       verbose=hp.verbose,\n",
    "                       fixed_limit=False)\n",
    "\n",
    "\n",
    "# train_data = DataLoader(ds, batch_size=hp.batch_size, shuffle=True, num_workers=hp.num_workers)\n",
    "# train_data = DataLoader(ds, batch_size=8, shuffle=True, num_workers=hp.num_workers)\n",
    "\n",
    "# batch = next(iter(train_data))\n",
    "\n",
    "# for idx, (complex, mag, label) in enumerate(train_data):\n",
    "#     print(idx, complex.shape)\n",
    "#     print(idx, mag.shape)\n",
    "#     print(idx, label)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DGL = DeepGriffinLim(blocks=4)\n",
    "\n",
    "# x = batch[0]\n",
    "# mag = batch[1]\n",
    "\n",
    "# print(f'x shape: {x.shape}')\n",
    "# print(f'x dtype: {x.dtype}')\n",
    "\n",
    "# print(f'mag shape: {mag.shape}')\n",
    "# print(f'mag dtype: {mag.dtype}')\n",
    "\n",
    "# DGL(x,mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataLoader(ds, batch_size=1, shuffle=True, num_workers=hp.num_workers)\n",
    "\n",
    "batch = next(iter(train_data))\n",
    "\n",
    "comp, mag, label = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Training loop\n",
    "from tqdm import tqdm\n",
    "model = DeepGriffinLim(blocks=10)\n",
    "train_data = DataLoader(ds, batch_size=8, shuffle=True, num_workers=hp.num_workers)\n",
    "\n",
    "def train(model, data_loader, device,epochs=10):\n",
    "    \n",
    "\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    criterion = torch.nn.L1Loss(reduction='None')\n",
    "\n",
    "\n",
    "    batch = next(iter(train_data))\n",
    "\n",
    "    # Initialise the noisy signal\n",
    "    comp, mag, label = batch\n",
    "    noise = torch.randn_like(comp, dtype=torch.complex64)\n",
    "    comp = comp + noise\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        comp, mag, label = batch\n",
    "\n",
    "        noise = torch.randn_like(comp, dtype=torch.complex64)\n",
    "        comp = comp + noise\n",
    "        comp = comp.to(device)\n",
    "        mag = mag.to(device)\n",
    "        \n",
    "        layer_outputs, final_out, residual = model(x=comp, mag=mag)\n",
    "\n",
    "        loss = criterion(residual, dnn_out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # if epoch % 2 == 0:\n",
    "        #     print(f'Loss: {loss.item()}')\n",
    "        # if epoch % 2 == 0:\n",
    "        print(f'Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "\n",
    "# train(model, train_data, 'cpu',epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2526)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,1,513,200,dtype=torch.complex64)\n",
    "\n",
    "y = torch.randn(4,1,513,200,dtype=torch.complex64)\n",
    "\n",
    "nn.L1Loss()(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([513, 282])\n",
      "torch.complex64\n"
     ]
    }
   ],
   "source": [
    "print(batch[0][0][0].shape)\n",
    "print(batch[0][0][0].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DeepGriffinLim(blocks=10)\n",
    "\n",
    "# comp, mag, label = batch\n",
    "\n",
    "# reconstruct, dnn_out, residual = model(comp,mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_out[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch = next(iter(train_data))\n",
    "\n",
    "def frequency_shift(stft, sr, N=513, L=512):\n",
    "    import numpy as np\n",
    "    \n",
    "    # Create a time-frequency grid for the frequency shift\n",
    "    k = np.arange(N)[:, None]  # Frequency bin indices, column vector\n",
    "    l = np.arange(stft.shape[1])  # Frame indices\n",
    "    \n",
    "    freq_shift = np.exp(-1j * (2 * np.pi/ N) * k * l * L )\n",
    "    \n",
    "    # Shift to baseband\n",
    "    baseband_stft_matrix = stft * freq_shift\n",
    "    \n",
    "    # Calculate and unwrap phase\n",
    "    phase = np.angle(baseband_stft_matrix)\n",
    "    unwrapped_phase = np.unwrap(phase, axis=1)  # Unwrap phase along the time axis\n",
    "    \n",
    "    # Calculate phase difference between neighboring frames\n",
    "    phase_diff = np.diff(unwrapped_phase, axis=1)\n",
    "    \n",
    "    return phase_diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def visualize_complex_tensor(tensor, phase_only=False):\n",
    "    tensor = tensor.detach()\n",
    "\n",
    "    # Separate the real and imaginary parts of the complex tensor\n",
    "    real = tensor.abs()\n",
    "    imag = tensor.angle()\n",
    "    amptodb = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "    if not phase_only:\n",
    "        # Create a grid of subplots for real and imaginary parts\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(20, 6))\n",
    "\n",
    "\n",
    "        # Plot the real part\n",
    "        im1 = axs[0].imshow(amptodb(real), cmap='magma')\n",
    "        axs[0].set_title('Mag')\n",
    "\n",
    "        # Plot the imaginary part\n",
    "        im2 = axs[1].imshow(imag, cmap='Blues')\n",
    "        axs[1].set_title('Phase')\n",
    "\n",
    "        # Add color barc\n",
    "        fig.colorbar(im1, ax=axs[0])\n",
    "        fig.colorbar(im2, ax=axs[1])\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "\n",
    "        return real, imag\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(20, 6))\n",
    "        im1 = axs.imshow(imag, cmap='magma')\n",
    "        axs.set_title('Phase')\n",
    "        fig.colorbar(im1, ax=axs)\n",
    "        plt.show()\n",
    "\n",
    "        return imag\n",
    "\n",
    "\n",
    "\n",
    "# visualize_complex_tensor(reconstruct[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn_like(batch[0][0][0], dtype=torch.complex64)\n",
    "\n",
    "# real , imag = visualize_complex_tensor(batch[0][0][0],phase_only=False)\n",
    "# imag2 = visualize_complex_tensor(batch[0][0][0],phase_only=True)\n",
    "\n",
    "\n",
    "# print(imag2.shape)\n",
    "\n",
    "\n",
    "# phase_diff = frequency_shift(imag, 48000)\n",
    "\n",
    "# sr = 48000\n",
    "# plt.figure(figsize=(15,6))\n",
    "# librosa.display.specshow(phase_diff,\n",
    "#                          sr=sr,\n",
    "#                          x_axis='time',\n",
    "#                          y_axis='linear')\n",
    "# plt.colorbar(format=\"%+2.f\")\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
