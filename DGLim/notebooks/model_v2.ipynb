{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from DGLim.data import *\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convGLU(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1, kernel_size=(7,7), padding='same', batchnorm=False):\n",
    "        super().__init__()\n",
    "        if padding == 'same':\n",
    "            padding = (kernel_size[0]//2, kernel_size[1]//2)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels * 2, kernel_size, padding=padding)  # 2D convolutional layer\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation function\n",
    "        if batchnorm:\n",
    "            self.conv = nn.Sequential(\n",
    "                self.conv,\n",
    "                nn.BatchNorm2d(out_channels * 2)  # Batch normalization layer\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Apply convolutional layer\n",
    "        channel = x.shape[1]  # Get the number of channels\n",
    "\n",
    "        x = x[:, :channel//2, :, :] * self.sigmoid(x[:, channel//2:, :, :])  # Apply GLU (Gated Linear Unit)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self,padding=None,additional_conv=False):\n",
    "        super().__init__()\n",
    "        self._hidden_channels = 32\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(7, self._hidden_channels, (11,11), padding=padding) if additional_conv else nn.Identity(), # in_channel = 6 because we concatenate the real and imag part of the complex spectrogram\n",
    "            convGLU(self._hidden_channels if additional_conv else 7, self._hidden_channels, (11,11), padding='same'))\n",
    "        \n",
    "        self.mid = nn.Sequential(\n",
    "            nn.Conv2d(self._hidden_channels, self._hidden_channels, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels, self._hidden_channels, (7,3), padding='same'),\n",
    "            nn.Conv2d(self._hidden_channels, self._hidden_channels, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels, self._hidden_channels, (7,3), padding='same'),\n",
    "        )\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(self._hidden_channels, 1, (7,3), padding=(7//2, 3//2)) if additional_conv else nn.Identity(),\n",
    "            convGLU(self._hidden_channels,self._hidden_channels, (7,3), padding='same'),\n",
    "            nn.Conv2d(self._hidden_channels, 2, (7,3), padding=(7//2, 3//2)),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        residual = x\n",
    "        x = self.mid(x)\n",
    "        x += residual\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DGL_block(nn.Module):\n",
    "    def __init__(self,blocks=10, n_fft=1024, hop_size=512, win_size=1024, window='hann_window'):\n",
    "        super().__init__()\n",
    "        self.dnn = DNN()\n",
    "\n",
    "    def stft(self, x, n_fft=1024, hop_size=512, win_size=1024):\n",
    "        return torch.stft(x, n_fft=n_fft, hop_length=hop_size, win_length=win_size, return_complex=True)\n",
    "\n",
    "    def istft(self, x, n_fft=1024, hop_size=512, win_size=1024):\n",
    "        return torch.istft(x, n_fft=n_fft, hop_length=hop_size, win_length=win_size)\n",
    "\n",
    "    def magswap(self, mag, x_tilda):\n",
    "        return mag * x_tilda / torch.abs(x_tilda)\n",
    "\n",
    "    def forward(self,x_tilda, mag, added_depth=1):\n",
    "        # step one is the P_a step\n",
    "\n",
    "        y_tilda = self.magswap(mag=mag,x_tilda=x_tilda)\n",
    "\n",
    "        z_tilda = self.stft(self.istft(y_tilda.squeeze(1)))\n",
    "\n",
    "        dnn_in = self.transform_to_float([x_tilda, y_tilda, z_tilda.unsqueeze(1)])\n",
    "        dnn_in = torch.cat([dnn_in, mag], dim=1)\n",
    "\n",
    "        dnn_out = self.dnn(dnn_in)\n",
    "        residual  = torch.complex(dnn_out[:,0,...], dnn_out[:,1,...])\n",
    "\n",
    "        x_tilda = (z_tilda - residual).unsqueeze_(1)\n",
    "                \n",
    "        final = self.magswap(mag=mag,x_tilda=x_tilda)\n",
    "        return z_tilda.unsqueeze_(1), residual.unsqueeze_(1), final, subblock_out\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_to_float(tensor_list: list):\n",
    "        output = []\n",
    "        for idx, i in enumerate(range(len(tensor_list))):\n",
    "            if tensor_list[i].dtype == torch.complex64 and tensor_list[i].dim() == 4:\n",
    "                output.append(torch.cat([tensor_list[i].real, tensor_list[i].imag], dim=1))\n",
    "            else:\n",
    "                print(f'Input {idx} is not a complex tensor with 4 dimensions')\n",
    "                return None\n",
    "\n",
    "        return torch.cat(output, dim=1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m weight_decay \u001b[39m=\u001b[39m \u001b[39m0.0001\u001b[39m\n\u001b[1;32m      9\u001b[0m train_data \u001b[39m=\u001b[39m DataLoader(ds, batch_size\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mnum_workers)\n\u001b[0;32m---> 12\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39mweight_decay)\n\u001b[1;32m     13\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mL1Loss(reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msum\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m model \u001b[39m=\u001b[39m DeepGriffinLim(blocks\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# simple training loop \n",
    "# Hyperparameters\n",
    "\n",
    "# Hyperparams\n",
    "epochs = 3\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.0001\n",
    "\n",
    "train_data = DataLoader(ds, batch_size=hp.batch_size, shuffle=True, num_workers=hp.num_workers)\n",
    "\n",
    "\n",
    "# Model \n",
    "model = DGL_block()\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "criterion = nn.L1Loss(reduction='sum')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch = next(iter(train_data))\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     clear, noisy, mag, label = batch\n",
    "#     # Forward pass\n",
    "    \n",
    "#     z_tilda, residual, final, subblock_out = model(x_tilda=noisy, mag=mag)\n",
    "\n",
    "#     z_tilda_for_loss = convert_from_complex(z_tilda)\n",
    "#     residual_for_loss = convert_from_complex(residual)\n",
    "#     clear_for_loss = convert_from_complex(clear)\n",
    "\n",
    "\n",
    "\n",
    "#     print(z_tilda_for_loss[:,1:,...].shape)\n",
    "\n",
    "#     # Compute loss\n",
    "#     loss = criterion(z_tilda_for_loss[:,1:,...] - clear_for_loss[:,1:,...], residual_for_loss[:,1:,...])\n",
    "\n",
    "#     # Backward pass\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     # Print loss\n",
    "#     print(f'Epoch: {epoch} Loss: {loss.item()}')\n",
    "\n",
    "#     phase_2 = torch.angle(final)\n",
    "\n",
    "#     librosa.display.specshow((phase_2[0][0]).detach().numpy(),\n",
    "#         sr=48000,\n",
    "#         x_axis='time',\n",
    "#         y_axis='linear',\n",
    "#         # vmin=0,\n",
    "#         # vmax=44100//2\n",
    "#         )\n",
    "#     plt.colorbar(format=\"%+2.f\")\n",
    "#     plt.show() \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
